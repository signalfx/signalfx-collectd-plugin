#!/usr/bin/python

import json
import fcntl
import array
import os
import re
import struct
import socket
import sys
import string
import platform
import signal
import subprocess
import time
import binascii
import StringIO
import gzip

import requests

if __name__ != '__main__':
    import collectd

PLUGIN_NAME = 'signalfx-metadata'
METADATA_HASH = ""
METADATA = {}
API_TOKEN = ""
TIMEOUT = 10
POST_URL = "https://ingest.signalfx.com/v1/collectd"
VERSION = "0.0.3"
NOTIFY_LEVEL = -1
HOST_TYPE_INSTANCE = "host-meta-data"
TOP_TYPE_INSTANCE = "top-info"
TYPE = "objects"
FIRST = True
AWS = True
PROCESS_INFO = True
INTERVAL = 10
LAST = 0
FUDGE = 0.1  # fudge to check intervals


class LargeNotif:
    """
    Used because the Python plugin supplied notification does not provide
    us with enough space
    """
    host = platform.node()
    message = ""
    plugin = PLUGIN_NAME
    plugin_instance = ""
    severity = 4
    time = 0
    type = TYPE
    type_instance = ""

    def __repr__(self):
        return 'PUTNOTIF %s/%s-%s/%s-%s %s' % (self.host, self.plugin,
                                               self.plugin_instance,
                                               self.type, self.type_instance,
                                               self.message)


def log(param):
    """ log messages and understand if we're in collectd or a program """
    if __name__ != '__main__':
        collectd.info("%s: %s" % (PLUGIN_NAME, param))
    else:
        sys.stderr.write("%s\n" % param)


def plugin_config(conf):
    """
    :param conf:
      https://collectd.org/documentation/manpages/collectd-python.5.shtml#config

    Parse the config object for config parameters:
      ProcessInfo: true or false, whether or not to collect process
        information. Default is true.
      Notifications: true or false, whether or not to emit notifications
      if Notifications is true:
        URL: where to POST the notifications to
        Token: what auth to send along
        Timeout: timeout for the POST
        NotifyLevel: what is the lowest level of notification to emit.
          Default is to only emit notifications generated by this plugin
    """

    for kv in conf.children:
        if kv.key == 'Notifications':
            if kv.values[0]:
                collectd.register_notification(receive_notifications)
        elif kv.key == 'ProcessInfo':
            if kv.values[0]:
                global PROCESS_INFO
                PROCESS_INFO = True
        elif kv.key == 'URL':
            global POST_URL
            POST_URL = kv.values[0]
        elif kv.key == 'Token':
            global API_TOKEN
            API_TOKEN = kv.values[0]
        elif kv.key == 'Timeout':
            global TIMEOUT
            TIMEOUT = int(kv.values[0])
        elif kv.key == 'Interval':
            global INTERVAL
            INTERVAL = int(kv.values[0])
        elif kv.key == 'NotifyLevel':
            global NOTIFY_LEVEL
            if string.lower(kv.values[0]) == "okay":
                NOTIFY_LEVEL = 4
            elif string.lower(kv.values[0]) == "warning":
                NOTIFY_LEVEL = 2
            elif string.lower(kv.values[0]) == "failure":
                NOTIFY_LEVEL = 1
        else:
            raise Exception("unknown config parameter '%s'" % kv.key)


def send():
    """
    Send proof-of-life datapoint, top, and notifications if interval elapsed

    Don't send any meta-information on first run just datapoint.
    This removes the race condition that could possibly exist with the host
    dimensions existing
    """
    global LAST
    diff = time.time() - LAST + FUDGE
    if diff < INTERVAL:
        log("interval not expired %s" % str(diff))
        return

    LAST = time.time()
    send_datapoint()
    send_top()

    global FIRST
    if FIRST:
        FIRST = False
        return

    send_notifications()


def all_interfaces():
    """
    source # http://bit.ly/1K8LIFH
    could use netifaces but want to package as little code as possible

    :return: all ip addresses by interface
    """
    is_64bits = sys.maxsize > 2 ** 32
    struct_size = 40 if is_64bits else 32
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    max_possible = 8  # initial value
    while True:
        _bytes = max_possible * struct_size
        names = array.array('B')
        for i in range(0, _bytes):
            names.append(0)
        outbytes = struct.unpack('iL', fcntl.ioctl(
            s.fileno(),
            0x8912,  # SIOCGIFCONF
            struct.pack('iL', _bytes, names.buffer_info()[0])
        ))[0]
        if outbytes == _bytes:
            max_possible *= 2
        else:
            break
    namestr = names.tostring()
    ifaces = []
    for i in range(0, outbytes, struct_size):
        iface_name = bytes.decode(namestr[i:i + 16]).split('\0', 1)[0]
        iface_addr = socket.inet_ntoa(namestr[i + 20:i + 24])
        ifaces.append((iface_name, iface_addr))

    return ifaces


def get_interfaces(host_info={}):
    """populate host_info with the ipaddress and fqdn for each interface"""
    for interface, ipaddress in all_interfaces():
        if ipaddress == "127.0.0.1":
            continue
        host_info["ipaddress_" + interface] = ipaddress
        host_info["fqdn_" + interface] = socket.getfqdn(ipaddress)
    return host_info


def get_cpu_info(host_info={}):
    """populate host_info with cpu information"""
    with open("/proc/cpuinfo") as f:
        nb_cpu = 0
        nb_cores = 0
        nb_units = 0
        for p in f.readlines():
            if ':' in p:
                x, y = map(lambda x: x.strip(), p.split(':', 1))
                if x.startswith("physical id"):
                    if nb_cpu < int(y):
                        nb_cpu = int(y)
                if x.startswith("cpu cores"):
                    if nb_cores < int(y):
                        nb_cores = int(y)
                if x.startswith("processor"):
                    if nb_units < int(y):
                        nb_units = int(y)
                if x.startswith("model name"):
                    model = y

        nb_cpu += 1
        nb_units += 1
        host_info["cpu_model"] = model
        host_info["physical_cpus"] = str(nb_cpu)
        host_info["cpu_cores"] = str(nb_cores)
        host_info["logical_cpus"] = str(nb_units)

    return host_info


def get_kernel_info(host_info={}):
    """
    gets kernal information from platform, relies on the restore_sigchld
    call above to work on python 2.6
    """
    try:
        host_info["kernel_name"] = platform.system()
        host_info["kernel_release"] = platform.release()
        host_info["kernel_version"] = platform.version()
        host_info["machine"] = platform.machine()
        host_info["processor"] = platform.processor()
    except:
        log("still seeing exception in platform module")

    return host_info


def get_aws_info(host_info={}):
    """
    call into aws to get some information about the instance, timeout really
    small for non aws systems and only try the once per startup
    """
    global AWS
    if not AWS:
        return host_info

    url = "http://169.254.169.254/latest/dynamic/instance-identity/document"
    try:
        response = requests.get(url, timeout=0.1)
        if response.ok:
            identity = json.loads(response.text)
            want = {
                'availability_zone': 'availabilityZone',
                'instance_type': 'instanceType',
                'instance_id': 'instanceId',
                'image_id': 'imageId',
                'account_id': 'accountId',
                'region': 'region',
                'architecture': 'architecture',
            }
            for k, v in iter(want.items()):
                host_info["aws_" + k] = identity[v]
    except:
        log("not an aws box")
        AWS = False

    return host_info


def popen(command):
    """ using subprocess instead of check_output for 2.6 comparability """
    output = subprocess.Popen(command, stdout=subprocess.PIPE).communicate()[0]
    return output.strip()


def get_collectd_version(host_info={}):
    """
    exec the pid (which will be collectd) with help and parse the help
    message for the version information
    """
    host_info["collectd_version"] = "UNKNOWN"
    try:
        pid = os.getpid()
        output = popen(["/proc/%d/exe" % pid, "-h"])
        regexed = re.search("collectd (.*), http://collectd.org/",
                            output.decode())
        if regexed:
            host_info["collectd_version"] = regexed.groups()[0]
    except Exception as e:
        log("trying to parse collectd version failed %s" % e)

    return host_info


def get_linux_version(host_info={}):
    """
    read /etc/lsb-release file for the version information
    """
    try:
        with open("/etc/lsb-release") as f:
            for line in f.readlines():
                regexed = re.search('DISTRIB_DESCRIPTION="(.*)"', line)
                if regexed:
                    host_info["linux_version"] = regexed.groups()[0]
                    break
    except:
        log("not a supported version of linux")
    return host_info


def send_top():
    """
    Parse top unless told not to
    filter out any zeros and common values to save space send it directly
    without going through collectd mechanisms because it is too large
    """
    if not PROCESS_INFO:
        return

    top = {}
    response = {"v": VERSION, "t": top}  # send version up with the values
    p1 = subprocess.Popen(["top", "-b", "-n1"], stdout=subprocess.PIPE)
    # filter ansi escape sequences
    p2 = subprocess.Popen(["sed", "-r",
                           "s/\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[m|K]//g"],
                          stdin=p1.stdout, stdout=subprocess.PIPE)
    top_raw = p2.communicate()[0].strip()

    read = False
    top_raw = top_raw.decode()
    for line in top_raw.split("\n"):
        pieces = line.strip().split()
        if len(pieces) < 12:
            continue
        if pieces[0] == 'PID':
            read = True
            continue
        if not read:
            continue
        top[int(pieces[0])] = [
            pieces[1],  # user
            pieces[2],  # priority
            pieces[3],  # nice value, could be int
            pieces[4],  # virtual memory size (KiB) can contain letters like G
            pieces[5],  # resident memory size (KiB) can contain letters like G
            pieces[6],  # shared memory size (KiB) can contain letters like G
            pieces[7],  # process status
            pieces[8],  # % cpu, could be float
            pieces[9],  # % mem, could be float
            pieces[10],  # cpu time in hundredths
            " ".join(pieces[11:len(pieces) - 1]),  # command
        ]
    s = json.dumps(response, separators=(',', ':'))
    # compressed = zlib.compress(s.encode("utf-8"))

    out = StringIO.StringIO()
    with gzip.GzipFile(fileobj=out, mode="w") as f:
        f.write(s)
    compressed = out.getvalue()
    base64 = binascii.b2a_base64(compressed)
    notif = LargeNotif()
    notif.plugin_instance = TOP_TYPE_INSTANCE
    notif.message = base64
    notif.type_instance = TOP_TYPE_INSTANCE
    receive_notifications(notif)


def get_host_info():
    """ aggregate all host info """
    host_info = get_interfaces({})
    get_cpu_info(host_info)
    get_kernel_info(host_info)
    get_aws_info(host_info)
    get_collectd_version(host_info)
    get_linux_version(host_info)
    host_info["metadata_version"] = VERSION
    return host_info


def mapdiff(host_info, old_host_info):
    """
    diff old and new host_info for additions of modifications
    don't look for removals as they will likely be spurious
    """
    diff = {}
    for k, v in iter(host_info.items()):
        if k not in old_host_info:
            diff[k] = v
        elif old_host_info[k] != v:
            diff[k] = v
    return diff


def putval(pname, metric, val):
    """Create collectd metric"""

    if __name__ != "__main__":
        collectd.Values(plugin=PLUGIN_NAME,
                        plugin_instance=pname,
                        meta={'0': True},
                        type=val[1].lower(),
                        type_instance=metric,
                        values=[val[0]]).dispatch()
    else:
        h = platform.node()
        print('PUTVAL %s/%s/%s-%s interval=%d N:%s' % (
            h, PLUGIN_NAME, val[1].lower(), metric, INTERVAL, val[0]))


def get_uptime():
    """get uptime for machine"""
    with open("/proc/uptime") as f:
        pieces = f.read()
        uptime, idle_time = pieces.split()
        return uptime

    return None


def send_datapoint():
    """write proof-of-life datapoint"""
    putval("", "sf.host-uptime", [get_uptime(), "gauge"])


def putnotif(property_name, message, plugin_name=PLUGIN_NAME,
             type_instance=HOST_TYPE_INSTANCE, type=TYPE):
    """Create collectd notification"""
    if __name__ != "__main__":
        notif = collectd.Notification(plugin=plugin_name,
                                      plugin_instance=property_name,
                                      type_instance=type_instance,
                                      type=type)
        notif.severity = 4  # OKAY
        notif.message = message
        notif.dispatch()
    else:
        h = platform.node()
        print('PUTNOTIF %s/%s-%s/%s-%s %s' % (h, plugin_name, property_name,
                                              type, type_instance, message))


def write_notifications(host_info):
    """emit any new notifications"""
    for property_name, property_value in iter(host_info.items()):
        putnotif(property_name, property_value)


def send_notifications():
    """
    only send notifications if metadata has changed
    changed defined by add or modify
    """
    global METADATA_HASH
    global METADATA
    host_info = get_host_info()
    host_hash = hash(frozenset(host_info.items()))
    old_host_info, METADATA = METADATA, host_info
    if METADATA_HASH != host_hash:
        METADATA_HASH = host_hash
        if old_host_info:
            host_info = mapdiff(host_info, old_host_info)

        write_notifications(host_info)


def get_severity(severity_int):
    """helper meethod to swap severities"""
    return {
        1: "FAILURE",
        2: "WARNING",
        4: "OKAY"
    }[severity_int]


def receive_notifications(notif):
    """
    callback to consume notifications from collectd and emit them to SignalFx.
    callback will only be called if Notifications was configured to be true.
    Only send notifications created by other plugs which are above or equal
    the configured NotifyLevel.
    """
    if not notif:
        return

    if __name__ == "__main__":
        log(notif)
        return

    if not API_TOKEN:
        return

    notif_dict = {}
    # because collectd c->python is a bit limited and lacks __dict__
    for x in ['host', 'message', 'plugin', 'plugin_instance', 'severity',
              'time', 'type', 'type_instance']:
        notif_dict[x] = getattr(notif, x, "")

    # emit notifications that are ours, or satisfy the notify level
    if notif_dict['plugin'] != PLUGIN_NAME and notif_dict['type'] != TYPE \
            and notif_dict['type_instance'] not in [HOST_TYPE_INSTANCE, TOP_TYPE_INSTANCE] \
            and notif_dict["severity"] > NOTIFY_LEVEL:
        log("event ignored: " + str(notif_dict))
        return

    if not notif_dict["time"]:
        notif_dict["time"] = time.time()
    if not notif_dict["host"]:
        notif_dict["host"] = platform.node()

    notif_dict["severity"] = get_severity(notif_dict["severity"])
    data = json.dumps([notif_dict])
    headers = {"Content-Type": "application/json"}
    if API_TOKEN != "":
        headers["X-SF-TOKEN"] = API_TOKEN
    req = requests.post(POST_URL, data=data, headers=headers, timeout=TIMEOUT)
    sys.stdout.write(req.text.strip())
    if not req.ok:
        log("unsuccessful code: %d response: %s" % (req.status_code, req.text))


def restore_sigchld():
    """
    Restores the SIGCHLD handler if needed

    See https://github.com/deniszh/collectd-iostat-python/issues/2 for
    details.
    """
    try:
        platform.system()
    except:
        log("executing SIGCHLD workaround")
        signal.signal(signal.SIGCHLD, signal.SIG_DFL)


if __name__ != "__main__":
    # when running inside plugin
    collectd.register_init(restore_sigchld)
    collectd.register_config(plugin_config)
    collectd.register_read(send)
else:
    # outside plugin just collect the info
    restore_sigchld()
    send()
    log(json.dumps(get_host_info(), sort_keys=True,
                   indent=4, separators=(',', ': ')))
    if len(sys.argv) < 2:
        while True:
            time.sleep(INTERVAL)
            send()
