#!/usr/bin/python

import json
import fcntl
import array
import os
import re
import struct
import socket
import sys
import string
import platform
import urllib2
import signal
import time
import subprocess

if __name__ != '__main__':
    import collectd

PLUGIN_NAME = 'signalfx-metadata'
METADATA_HASH = ""
METADATA = {}
API_TOKEN = ""
TIMEOUT = 10
POST_URL = "https://ingest.signalfx.com/v1/collectd"
VERSION = "0.0.1"
NOTIFY_LEVEL = -1
TYPE_INSTANCE = "host-meta-data"
TYPE = "objects"
FIRST = True
AWS = True


def log(param):
    """ log messages and understand if we're in collectd or a program """
    if __name__ != '__main__':
        collectd.info("%s: %s" % (PLUGIN_NAME, param))
    else:
        print param


def plugin_config(conf):
    """
    :param conf:
      https://collectd.org/documentation/manpages/collectd-python.5.shtml#config

    Parse the config object for config parameters:
      Notifications: true or false, whether or not to emit notifications
      if Notifications is true:
        URL: where to POST the notifications to
        Token: what auth to send along
        Timeout: timeout for the POST
        NotifyLevel: what is the lowest level of notification to emit.
          Default is to only emit notifications generated by this plugin
    """

    for kv in conf.children:
        if kv.key == 'Notifications':
            if kv.values[0]:
                collectd.register_notification(receive_notifications)
        elif kv.key == 'URL':
            global POST_URL
            POST_URL = kv.values[0]
        elif kv.key == 'Token':
            global API_TOKEN
            API_TOKEN = kv.values[0]
        elif kv.key == 'Timeout':
            global TIMEOUT
            TIMEOUT = int(kv.values[0])
        elif kv.key == 'NotifyLevel':
            global NOTIFY_LEVEL
            if string.lower(kv.values[0]) == "okay":
                NOTIFY_LEVEL = 4
            elif string.lower(kv.values[0]) == "warning":
                NOTIFY_LEVEL = 2
            elif string.lower(kv.values[0]) == "failure":
                NOTIFY_LEVEL = 1
        else:
            raise Exception("unknown config parameter '%s'" % kv.key)


def send():
    """
    Send proof-of-life datapoint and notifications

    Don't send any meta-information on first run just datapoint.
    This removes the race condition that could possibly exist with the host
    dimensions existing
    """
    send_datapoint()

    global FIRST
    if FIRST:
        FIRST = False
        return

    send_notifications()


def all_interfaces():
    """
    source # http://bit.ly/1K8LIFH
    could use netifaces but want to package as little code as possible

    :return: all ip addresses by interface
    """
    is_64bits = sys.maxsize > 2 ** 32
    struct_size = 40 if is_64bits else 32
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    max_possible = 8  # initial value
    while True:
        bytes = max_possible * struct_size
        names = array.array('B', '\0' * bytes)
        outbytes = struct.unpack('iL', fcntl.ioctl(
            s.fileno(),
            0x8912,  # SIOCGIFCONF
            struct.pack('iL', bytes, names.buffer_info()[0])
        ))[0]
        if outbytes == bytes:
            max_possible *= 2
        else:
            break
    namestr = names.tostring()
    return [(namestr[i:i + 16].split('\0', 1)[0],
             socket.inet_ntoa(namestr[i + 20:i + 24]))
            for i in range(0, outbytes, struct_size)]


def get_interfaces(host_info={}):
    """populate host_info with the ipaddress and fqdn for each interface"""
    for interface, ipaddress in all_interfaces():
        if ipaddress == "127.0.0.1":
            continue
        host_info["ipaddress_" + interface] = ipaddress
        host_info["fqdn_" + interface] = socket.getfqdn(ipaddress)
    return host_info


def get_cpu_info(host_info={}):
    """populate host_info with cpu information"""
    with open("/proc/cpuinfo") as f:
        nb_cpu = 0
        nb_cores = 0
        nb_units = 0
        for p in f.readlines():
            if ':' in p:
                x, y = map(lambda x: string.strip(x), string.split(p, ':', 1))
                if x.startswith("physical id"):
                    if nb_cpu < int(y):
                        nb_cpu = int(y)
                if x.startswith("cpu cores"):
                    if nb_cores < int(y):
                        nb_cores = int(y)
                if x.startswith("processor"):
                    if nb_units < int(y):
                        nb_units = int(y)
                if x.startswith("model name"):
                    model = y

        nb_cpu += 1
        nb_units += 1
        host_info["cpu_model"] = model
        host_info["physical_cpus"] = str(nb_cpu)
        host_info["cpu_cores"] = str(nb_cores)
        host_info["logical_cpus"] = str(nb_units)

    return host_info


def get_kernel_info(host_info={}):
    """
    gets kernal information from platform, relies on the restore_sigchld
    call above to work on python 2.6
    """
    try:
        host_info["kernel_name"] = platform.system()
        host_info["kernel_release"] = platform.release()
        host_info["kernel_version"] = platform.version()
        host_info["machine"] = platform.machine()
        host_info["processor"] = platform.processor()
    except:
        log("still seeing exception in platform module")

    return host_info


def get_aws_info(host_info={}):
    """
    call into aws to get some information about the instance, timeout really
    small for non aws systems and only try the once per startup
    """
    if not AWS:
        return host_info

    url = "http://169.254.169.254/latest/dynamic/instance-identity/document"
    try:
        req = urllib2.Request(url)
        response = urllib2.urlopen(req, timeout=0.1)
        identity = json.loads(response.read())
        want = {
            'availability_zone': 'availabilityZone',
            'instance_type': 'instanceType',
            'instance_id': 'instanceId',
            'image_id': 'imageId',
            'account_id': 'accountId',
            'region': 'region',
            'architecture': 'architecture',
        }
        for k, v in want.iteritems():
            host_info["aws_" + k] = identity[v]
    except:
        log("not an aws box")
        global AWS
        AWS = False

    return host_info


def popen(command):
    """ using subprocess instead of check_output for 2.6 comparability """
    output = subprocess.Popen(command, stdout=subprocess.PIPE).communicate()[0]
    return string.strip(output)


def get_collectd_version(host_info={}):
    """
    exec the pid (which will be collectd) with help and parse the help
    message for the version information
    """
    host_info["collectd_version"] = "UNKNOWN"
    try:
        pid = os.getpid()
        output = popen(["/proc/%d/exe" % pid, "-h"])
        regexed = re.search("collectd (.*), http://collectd.org/", output)
        if regexed:
            host_info["collectd_version"] = regexed.groups()[0]
    except Exception as e:
        log("trying to parse collectd version failed %s", e.message)

    return host_info


def get_host_info():
    """ aggregate all host info """
    host_info = get_interfaces({})
    get_cpu_info(host_info)
    get_kernel_info(host_info)
    get_aws_info(host_info)
    get_collectd_version(host_info)
    host_info["metadata_version"] = VERSION
    return host_info


def mapdiff(host_info, old_host_info):
    """
    diff old and new host_info for additions of modifications
    don't look for removals as they will likely be spurious
    """
    diff = {}
    for k, v in host_info.iteritems():
        if k not in old_host_info:
            diff[k] = v
        elif old_host_info[k] != v:
            diff[k] = v
    return diff


def putval(pname, metric, val):
    """Create collectd metric"""

    collectd.Values(plugin=PLUGIN_NAME,
                    plugin_instance=pname,
                    meta={'0': True},
                    type=val[1].lower(),
                    type_instance=metric,
                    values=[val[0]]).dispatch()


def send_datapoint():
    """write proof-of-life datapoint"""
    putval("ping", "sf.host-meta-data", [time.time(), "gauge"])


def putnotif(property_name, message):
    """Create collectd notification"""
    notif = collectd.Notification(plugin=PLUGIN_NAME,
                                  plugin_instance=property_name,
                                  type_instance=TYPE_INSTANCE,
                                  type=TYPE)
    notif.severity = 4  # OKAY
    notif.message = message
    notif.dispatch()


def write_notifications(host_info):
    """emit any new notifications"""
    for property_name, property_value in host_info.iteritems():
        putnotif(property_name, property_value)


def send_notifications():
    """
    only send notifications if metadata has changed
    changed defined by add or modify
    """
    global METADATA_HASH
    global METADATA
    host_info = get_host_info()
    host_hash = hash(frozenset(host_info.items()))
    old_host_info, METADATA = METADATA, host_info
    if METADATA_HASH != host_hash:
        METADATA_HASH = host_hash
        if old_host_info:
            host_info = mapdiff(host_info, old_host_info)

        write_notifications(host_info)


def get_severity(severity_int):
    return {
        1: "FAILURE",
        2: "WARNING",
        4: "OKAY"
    }[severity_int]


def receive_notifications(notif):
    """
    callback to consume notifications from collectd and emit them to SignalFx.
    callback will only be called if Notifications was configured to be true.
    Only send notifications created by other plugs which are above or equal
    the configured NotifyLevel.
    """
    notif_dict = {}
    # because collectd c->python is a bit limited and lacks __dict__
    for x in ['host', 'message', 'plugin', 'plugin_instance', 'severity',
              'time', 'type', 'type_instance']:
        notif_dict[x] = notif.__getattribute__(x)

    # emit notifications that are ours, or satisfy the notify level
    if notif_dict['plugin'] != PLUGIN_NAME and notif_dict['type'] != TYPE \
            and notif_dict['type_instance'] != TYPE_INSTANCE \
            and notif_dict["severity"] > NOTIFY_LEVEL:
        print notif_dict
        return

    notif_dict["severity"] = get_severity(notif_dict["severity"])
    data = json.dumps([notif_dict])
    headers = {"Content-Type": "application/json"}
    if API_TOKEN != "":
        headers["X-SF-TOKEN"] = API_TOKEN
    try:
        req = urllib2.Request(POST_URL, data, headers)
        r = urllib2.urlopen(req, timeout=TIMEOUT)
        sys.stdout.write(string.strip(r.read()))
    except urllib2.URLError as e:
        sys.stdout.write(str(e.reason))


def restore_sigchld():
    """
    Restores the SIGCHLD handler if needed

    See https://github.com/deniszh/collectd-iostat-python/issues/2 for
    details.
    """
    try:
        platform.system()
    except:
        log("executing SIGCHLD workaround")
        signal.signal(signal.SIGCHLD, signal.SIG_DFL)


if __name__ != "__main__":
    # when running inside plugin
    collectd.register_init(restore_sigchld)
    collectd.register_config(plugin_config)
    collectd.register_read(send)
else:
    # outside plugin just collect the info
    print get_host_info()
